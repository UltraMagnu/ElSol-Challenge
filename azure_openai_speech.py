# Importa las bibliotecas necesarias.
# 'os' para manejar variables de entorno.
# 'azure.cognitiveservices.speech' para el reconocimiento de voz y la s√≠ntesis de voz.
# 'openai' para interactuar con la API de Azure OpenAI.
from openai import AzureOpenAI
import azure.cognitiveservices.speech as speechsdk
import os
from dotenv import load_dotenv

# Carga las variables de entorno desde el archivo .env
load_dotenv()

# --- Configuraci√≥n de Azure OpenAI ---
# Inicializa el cliente de OpenAI con las credenciales de Azure.
# Las credenciales se obtienen de las variables de entorno.
try:
    client = AzureOpenAI(
        azure_endpoint=os.getenv("AZURE_OPENAI_API_ENDPOINT"),
        api_key=os.getenv("AZURE_OPENAI_API_KEY"),
        api_version="2025-01-01-preview"
    )
    # Define el ID del despliegue del modelo (chat) que se usar√°.
    deployment_id = os.getenv("AZURE_OPENAI_DEPLOYMENT")
except Exception as e:
    print(f"Error al configurar Azure OpenAI: {e}")
    exit()

# --- Configuraci√≥n de Azure Speech Service ---
# Configura las propiedades del servicio de voz (clave y regi√≥n).
try:
    speech_config = speechsdk.SpeechConfig(
        subscription=os.getenv("AZURE_SPEECH_KEY"), 
        region=os.getenv("AZURE_REGION")
    )
    # Define el idioma para el reconocimiento de voz.
    speech_config.speech_recognition_language = "es-ES" 
    # Define la voz para la s√≠ntesis de voz (ej. en-US-JennyNeural para ingl√©s, es-ES-ElviraNeural para espa√±ol).
    speech_config.speech_synthesis_voice_name = "es-ES-ElviraNeural"

    # Configura la entrada de audio (micr√≥fono predeterminado) y la salida (altavoz predeterminado).
    audio_config_in = speechsdk.audio.AudioConfig(use_default_microphone=True)
    audio_config_out = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)

    # Crea el reconocedor de voz.
    speech_recognizer = speechsdk.SpeechRecognizer(
        speech_config=speech_config, 
        audio_config=audio_config_in
    )
    # Crea el sintetizador de voz.
    speech_synthesizer = speechsdk.SpeechSynthesizer(
        speech_config=speech_config, 
        audio_config=audio_config_out
    )

except Exception as e:
    print(f"Error al configurar Azure Speech Service: {e}")
    exit()


def recognize_speech():
    """
    Escucha desde el micr√≥fono y reconoce el habla del usuario.
    Retorna la transcripci√≥n si es exitosa, o None en caso de error o no reconocimiento.
    """
    print("üì¢ Diga algo por favor...")
    result = speech_recognizer.recognize_once()

    if result.reason == speechsdk.ResultReason.RecognizedSpeech:
        print(f"üó£Ô∏è Reconocido: {result.text}")
        return result.text
    elif result.reason == speechsdk.ResultReason.NoMatch:
        print("ü§∑ No se pudo reconocer el habla.")
    elif result.reason == speechsdk.ResultReason.Canceled:
        # Manejo de errores de cancelaci√≥n.
        cancellation_details = result.cancellation_details
        print(f"‚ùå Reconocimiento cancelado: {cancellation_details.reason}")
        if cancellation_details.reason == speechsdk.CancellationReason.Error:
            print(f"Detalles del error: {cancellation_details.error_details}")
    return None

def ask_azure_openai(prompt):
    """
    Env√≠a una pregunta al chatbot de Azure OpenAI y reproduce la respuesta.
    """
    if not prompt:
        return

    print("ü§ñ Generando respuesta...")
    try:
        # Llama a la API de Azure OpenAI con el prompt del usuario.
        response = client.chat.completions.create(
            model=deployment_id,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7
        )
        
        # Extrae el texto de la respuesta.
        full_response_text = response.choices[0].message.content
        print(f"‚úÖ Respuesta del chatbot: {full_response_text}")

        # Sintetiza la respuesta para que el usuario la escuche.
        speech_synthesizer.speak_text_async(full_response_text).get()
    
    except Exception as e:
        print(f"Error al interactuar con el chatbot: {e}")

def main():
    """
    Funci√≥n principal que ejecuta el ciclo de reconocimiento y respuesta.
    """
    # Escucha al usuario y obtiene la transcripci√≥n.
    user_text = recognize_speech()

    # Si se reconoci√≥ el habla, env√≠a la transcripci√≥n al chatbot.
    if user_text:
        ask_azure_openai(user_text)

if __name__ == "__main__":
    main()
